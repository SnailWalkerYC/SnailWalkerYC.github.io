---
layout: post
title: My Conclusion in visual SLAM
date: 2019-07-24
Author: 来自中世界
categories: [technology]
tags: [cv, SLAM]
comments: true
---

In visual SLAM, depending on the camera types, we can divide vSLAM into mono-SLAM, stereo-SLAM and RGBD-SLAM. Different sensors have theis limitation. For instance, mono-camera will suffer from nont-scale and scale shift problem. stereo camera will suffer from high computation cost on matching and calibration accuracy problem. RGBD cameras like RealSense can run well in indoor scenarios, but in the outdoor environment, the distance measurement will suffer from light affection of the camera signal receiver. To recover the absolute scale of the camera poses, the IMU can be added into the mono-SLAM system, but there is one requirement for the excellent synchronization of IMU and camera time stamps. So the price of mono-IMU is rather expensive.


In visual mono SLAM, there are four combinations: sparse means utilizing a sub-set of points. Dense means using all points and geometry constrains added. Direct means using pixel information directly. Indirect means using inter-mediate information like feature, light flow, curvature. 

- Sparse + indirect: ORB-SLAM, PTAM 
- Dense + indirect: dense monocular depth estimation in complex dynamic scenes. 
- Dense + direct: DTAM, LSD-SLAM
- Sparse + direct: DSO

Direct method will utilize all pixel information, but it will be affected by automatic exposure, non-linear response function(gamma function, white balancing), lens attenuation, debayering artefacts and geometry distortions (rolling shutter). But direct method can get more finely geometry representation (pixel wise inverse depth) and more robust in sparse textured environment.

Sparse method will lose geometry prior information, but it will get better result in large scale environment. The geometry prior always exists bias. What’s more, sparse method can be calculated in real time with Schur Complement. Optimization part is using marginalization.


In this poster, I would like to talk more about mono-SLAM and some traditional SLAM methods: DSO, ORB and LSD.

The table below is the comparing of these methods:

| Methods  |      DSO      |  ORB |  LSD | 
|:----------------:|:----------------:|:----------------:|:---------------:|
| Dependency | *suitesparse and eigen3 (sparse matrix and matrix operation) OpenCV (used for image reading from database) Ziplib: read zip data; Pangolin: 3D visualization and GUI ; Sse2neon: ARM build needed. | *Pangolin: 3D visualization; *OpenCV 2.4.3+; *Eigen3; *DBoW2 (bag of words, modified);*g2o (graph optimization tool); ROS: optional | *ROS (use ROS) *OpenCV *Eigen3 *g2o The installed process is not clear |
| Saving Map | Supported(from output interface) |Supported((https://github.com/Jiankai-Sun/ORB_SLAM2_Enhanced) | Not clear (on Github, only map with variance and depth, no RGB cloud )
https://github.com/alexanderkoumis/lsd_slam/tree/rgb-pointcloud |
| Localization Module | No, purely visual odometry(https://github.com/JakobEngel/dso/issues/10) |Supported | Supported |
| Loop closure |No | Supported | Supported |
| Visualization | Cool | Not Cool  | Cool  |
| Code Quality | Normal | Normal | Good |
| Device | Mono, Stereo, RGB-D, Fusion with IMU | Mono, Stereo, RGB-D | Mono, Stereo,
 RGB-D |
| Robust | “Stable medium" | “Stable”  | Not Stable Outside |
| Open Source | Only mono and LDSO[1] | All | Only Mono |
| Platform | Ubuntu 14.04, 16.04, Mac OS, ARM platform. | Ubuntu 16.04, Ubuntu 14.04, Mac OS, iOS | Ubuntu 14.04, Ubuntu 16.04 |
| Rate fps | 30 | 20 | 25 |
| Advantage | Fast, dense map, less sensitive to moving object | Localization and loop closure  | Has Localization and loop closure, dense map |
| Disadvantage | Sensitive to light(I think our company has tech can fix this problem)
No loop closure and relocalization model(if accuracy is enough, there is no need for loop closure) | Sensitive to moving object, sparse map and less fast due to feature extraction | Worse than DSO in every aspect (speed, robust) |

Note:
- * means the lib is necessary.
- For visualization, the depth may be used to capture depth. 
- LSD Github: https://github.com/tum-vision/lsd_slam
- https://vision.in.tum.de/research/vslam/lsdslam
- DSO Github: https://github.com/JakobEngel/dso
- https://vision.in.tum.de/research/vslam/dso
- ORB SLAM: https://github.com/raulmur/ORB_SLAM2
- ^ test platform: i7-6600U 

#### Ref links:
```
[1]The SDO stereo and IMU fusion version have no open source, but someone reimplemented on Github: https://github.com/JiatianWu/stereo-dso
[2] Video Comparison between ORB & DSO: https://www.youtube.com/watch?v=EJwY-TFmHJY
[3] Comparison between LSD, DSO, ORB: https://www.youtube.com/watch?v=C6-xwSOOdqQ
[4] svo: https://github.com/uzh-rpg/rpg_svo  300frames/s but with huge error, so IMU is coupled with this method and get good result in this situation in quadcopter.
[5] SLAM Report: http://mac.xmu.edu.cn/valse2017/ppt/APR/VALSE-SLAM-2017-tp.pdf
[6] SLAM Analysis: https://people.eecs.berkeley.edu/~chaene/cvpr17tut/SLAM.pdf 
```

